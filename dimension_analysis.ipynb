{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "import glob\n",
    "import depthai  # depthai - access the camera and its data packets\n",
    "import blobconverter  # blobconverter - compile and download MyriadX neural network blobs\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = depthai.Pipeline()\n",
    "cam_rgb = pipeline.create(depthai.node.ColorCamera)\n",
    "cam_rgb.setPreviewSize(1280,720)\n",
    "cam_rgb.setInterleaved(False)\n",
    "\n",
    "#Creating a stream of the rgb camera and naming it \"rgb\"\n",
    "xout_rgb = pipeline.create(depthai.node.XLinkOut)\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "cam_rgb.preview.link(xout_rgb.input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = None\n",
    "coords = []\n",
    "def click_event(event, x, y, flags, params):\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        coords.append((x, y))\n",
    "        if len(coords) == 3:\n",
    "            coords.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import variables from the pickle file\n",
    "with open('calibration.pkl', 'rb') as f:\n",
    "    calibration = pickle.load(f)\n",
    "ret = calibration['ret']\n",
    "mtx = calibration['mtx']\n",
    "dist = calibration['dist']\n",
    "rvecs = calibration['rvecs']\n",
    "tvecs = calibration['tvecs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intrinsics:  [[897.65110375   0.         559.40540049]\n",
      " [  0.         885.60904869 374.39506256]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Communication exception - possible device error/misconfiguration. Original message 'Couldn't read data from stream: 'rgb' (X_LINK_ERROR)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Main host-side application loop\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# we try to fetch the data from nn/rgb queues. tryGet will return either the data packet or None if there isn't any\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     in_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mq_rgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtryGet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_rgb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# If the packet from RGB camera is present, we're retrieving the frame in OpenCV format using getCvFrame\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         frame \u001b[38;5;241m=\u001b[39m in_rgb\u001b[38;5;241m.\u001b[39mgetCvFrame()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Communication exception - possible device error/misconfiguration. Original message 'Couldn't read data from stream: 'rgb' (X_LINK_ERROR)'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "_cm = 35\n",
    "_scale = 10\n",
    "z_dist = _cm*_scale#cm\n",
    "with depthai.Device(pipeline) as device:\n",
    "    try:\n",
    "        calibData = device.readCalibration2()\n",
    "        lensPosition = calibData.getLensPosition(depthai.CameraBoardSocket.RGB)\n",
    "        intrinsics = calibData.getCameraIntrinsics(depthai.CameraBoardSocket.RGB)\n",
    "        print(\"intrinsics: \", mtx)\n",
    "        np_intrinsics = np.array(mtx)\n",
    "        np_intrinsics=np.linalg.inv(np_intrinsics)\n",
    "\n",
    "        # print(\"intrinsics: \", intrinsics)\n",
    "        if lensPosition:\n",
    "            cam_rgb.initialControl.setManualFocus(lensPosition)\n",
    "    except:\n",
    "        raise\n",
    "    # From this point, the Device will be in \"running\" mode and will start sending data via XLink\n",
    "\n",
    "    # To consume the device results, we get two output queues from the device, with stream names we assigned earlier\n",
    "    q_rgb = device.getOutputQueue(\"rgb\")\n",
    "\n",
    "    # Here, some of the default values are defined. Frame will be an image from \"rgb\" stream, detections will contain nn results\n",
    "    frame = None\n",
    "    detections = []\n",
    "\n",
    "    # Since the detections returned by nn have values from <0..1> range, they need to be multiplied by frame width/height to\n",
    "    # receive the actual position of the bounding box on the image\n",
    "    def frameNorm(frame, bbox):\n",
    "        normVals = np.full(len(bbox), frame.shape[0])\n",
    "        normVals[::2] = frame.shape[1]\n",
    "        return (np.clip(np.array(bbox), 0, 1) * normVals).astype(int)\n",
    "\n",
    "    img_counter = 0\n",
    "    # Main host-side application loop\n",
    "    while True:\n",
    "        # we try to fetch the data from nn/rgb queues. tryGet will return either the data packet or None if there isn't any\n",
    "        in_rgb = q_rgb.tryGet()\n",
    "\n",
    "        if in_rgb is not None:\n",
    "            # If the packet from RGB camera is present, we're retrieving the frame in OpenCV format using getCvFrame\n",
    "            frame = in_rgb.getCvFrame()\n",
    "            # print(frame.shape)\n",
    "\n",
    "\n",
    "        if frame is not None:\n",
    "            for c in coords:\n",
    "                cv2.circle(frame, c, 5, (255, 0, 0), -1)\n",
    "                if(len(coords)==2):\n",
    "                    cv2.line(frame, coords[0], coords[1], (255, 0, 0), 5)\n",
    "                    dist = np.linalg.norm(np.array(coords[0])-np.array(coords[1]))\n",
    "                    \n",
    "                    \n",
    "                    pix_coord_1 = np.array([coords[0][0], coords[0][1], z_dist])\n",
    "                    pix_coord_2 = np.array([coords[1][0], coords[1][1], z_dist])\n",
    "\n",
    "                    real_coord_1 = pix_coord_1 @ np_intrinsics\n",
    "                    real_coord_2 = pix_coord_2 @ np_intrinsics \n",
    "                    real_dist = np.linalg.norm(real_coord_1-real_coord_2)/_scale\n",
    "                    #cv2.putText(frame, \"cord 1: \" + str(real_coord_1), (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(frame, \"real_dist: \" + str(real_dist) + \" cm\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # After all the drawing is finished, we show the frame on the screen\n",
    "            cv2.imshow(\"image\", frame)\n",
    "\n",
    "        # at any time, you can press \"q\" and exit the main loop, therefore exiting the program itself\n",
    "        k = cv.waitKey(1)\n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bc538aba534c89b0a5c0076cf9b663a7efbcd0cd43af899552ce764c25285b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
